{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def datadir(*args):\n",
    "    return Path.cwd().parent.joinpath(\"data\", *args).resolve()\n",
    "\n",
    "\n",
    "path_heeten_data = datadir(\"GridFlexHeetenDataset.csv\")  # 61.49GB\n",
    "target_time_range = [\n",
    "    [\"2018-08-01 00:00:00+00:00\", \"2019-08-01 00:00:00+00:00\"],\n",
    "    [\"2019-08-01 00:00:00+00:00\", \"2020-08-01 00:00:00+00:00\"],\n",
    "]  # The data is from 2018-08-01T01:59:00+02:00 to 2020-08-31T23:58:00+02:00\n",
    "target_measurement = [\n",
    "    \"UNC_KW\",\n",
    "    \"TOTAL_KW\",\n",
    "    \"EXPORT_KW\",\n",
    "    \"IMPORT_KW\",\n",
    "    \"PV_KW\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house</th>\n",
       "      <th>appliance</th>\n",
       "      <th>measurement</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-01 01:59:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:00:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:01:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:02:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:03:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:04:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:05:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:06:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:07:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 02:08:00+02:00</th>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            house appliance measurement  value\n",
       "timestamp                                                     \n",
       "2018-08-01 01:59:00+02:00  House6   BATTERY  BATTERY_KW -0.037\n",
       "2018-08-01 02:00:00+02:00  House6   BATTERY  BATTERY_KW -0.037\n",
       "2018-08-01 02:01:00+02:00  House6   BATTERY  BATTERY_KW -0.033\n",
       "2018-08-01 02:02:00+02:00  House6   BATTERY  BATTERY_KW -0.041\n",
       "2018-08-01 02:03:00+02:00  House6   BATTERY  BATTERY_KW -0.034\n",
       "2018-08-01 02:04:00+02:00  House6   BATTERY  BATTERY_KW -0.033\n",
       "2018-08-01 02:05:00+02:00  House6   BATTERY  BATTERY_KW -0.025\n",
       "2018-08-01 02:06:00+02:00  House6   BATTERY  BATTERY_KW -0.028\n",
       "2018-08-01 02:07:00+02:00  House6   BATTERY  BATTERY_KW -0.028\n",
       "2018-08-01 02:08:00+02:00  House6   BATTERY  BATTERY_KW -0.028"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cat_house = CategoricalDtype(\n",
    "    categories=[f\"House{i}\" for i in range(1, 78)], ordered=True\n",
    ")  # We disregard \"HouseTest\", so \"HouseTest\" will resolve to NaN\n",
    "_cat_appliance = CategoricalDtype(\n",
    "    categories=[\"SMARTMETER\", \"PVMETER\", \"BATTERY\"], ordered=True\n",
    ")\n",
    "_cat_measurement = CategoricalDtype(\n",
    "    categories=[\n",
    "        \"BATTERY_EXPORT_KW\",\n",
    "        \"BATTERY_IMPORT_KW\",\n",
    "        \"BATTERY_KW\",\n",
    "        \"BATTERY_TARGET_KW\",\n",
    "        \"BATTERY_TARGET_MODE\",\n",
    "        \"CHARGE_MODE\",\n",
    "        \"CURRENT_PHASE_1\",\n",
    "        \"CURRENT_PHASE_2\",\n",
    "        \"CURRENT_PHASE_3\",\n",
    "        \"EXPORT_KW\",\n",
    "        \"EXPORT_KWH\",\n",
    "        \"GAS_USAGE_M3\",\n",
    "        \"IMPORT_KW\",\n",
    "        \"IMPORT_KWH\",\n",
    "        \"MAX_BATTERY_KW\",\n",
    "        \"MIN_BATTERY_KW\",\n",
    "        \"MOMENTARY_EXPORT_KW\",\n",
    "        \"MOMENTARY_IMPORT_KW\",\n",
    "        \"MOMENTARY_PV_KW\",\n",
    "        \"OPERATIONAL_STATE\",\n",
    "        \"PV_KW\",\n",
    "        \"PV_KWH\",\n",
    "        \"REQ_CHARGE_MODE\",\n",
    "        \"STATE_OF_CHARGE\",\n",
    "        \"TOTAL_KW\",\n",
    "        \"TOTAL_KWH\",\n",
    "        \"UNC_KW\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "dtype = {\n",
    "    \"house\": _cat_house,\n",
    "    \"appliance\": _cat_appliance,\n",
    "    \"measurement\": _cat_measurement,\n",
    "    \"value\": \"float64\",\n",
    "}\n",
    "# FIXME: solve mixed time offsets\n",
    "# CET: +01:00 (https://en.wikipedia.org/wiki/Central_European_Time)\n",
    "# CEST: +02:00 (https://en.wikipedia.org/wiki/Central_European_Summer_Time)\n",
    "small_df = pd.read_csv(\n",
    "    path_heeten_data,\n",
    "    nrows=10,\n",
    "    index_col=[\"timestamp\"],\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype=dtype,\n",
    ")\n",
    "small_df\n",
    "# small_df.groupby(\"house\", observed=True).describe()\n",
    "# small_df.loc[\"2018-08-01 00:00:00+00:00\":\"2018-08-01 12:08:00+00:00\"]\n",
    "# small_df.query(\"'2018-08-01 02:00:00+02:00' <= index <= '2018-08-01 02:05:00+02:00'\")  # \" <= index <= \".join(map(lambda x: \"'\" + x + \"'\", target_time_range[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2018-08-01 01:59:00+02:00 to 2018-08-01 02:08:00+02:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   timestamp    10 non-null     object  \n",
      " 1   house        10 non-null     category\n",
      " 2   appliance    10 non-null     category\n",
      " 3   measurement  10 non-null     category\n",
      " 4   value        10 non-null     float64 \n",
      "dtypes: category(3), float64(1), object(1)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dtype = {\n",
    "    \"timestamp\": str,\n",
    "    \"house\": _cat_house,\n",
    "    \"appliance\": _cat_appliance,\n",
    "    \"measurement\": _cat_measurement,\n",
    "    \"value\": \"float64\",\n",
    "}\n",
    "small_df = pd.read_csv(\n",
    "    path_heeten_data,\n",
    "    nrows=10,\n",
    "    # index_col=[\"timestamp\"],\n",
    "    # parse_dates=[\"timestamp\"],\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "# small_df.reindex(pd.to_datetime(small_df[\"timestamp\"]))\n",
    "small_df.set_index(pd.to_datetime(small_df[\"timestamp\"]), inplace=True)\n",
    "small_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>house</th>\n",
       "      <th>appliance</th>\n",
       "      <th>measurement</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-01T01:59:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-01T02:00:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-01T02:01:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-01T02:02:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-01T02:03:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-01T02:04:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-08-01T02:05:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-08-01T02:06:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-08-01T02:07:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-08-01T02:08:00+02:00</td>\n",
       "      <td>House6</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>BATTERY_KW</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp   house appliance measurement  value\n",
       "0  2018-08-01T01:59:00+02:00  House6   BATTERY  BATTERY_KW -0.037\n",
       "1  2018-08-01T02:00:00+02:00  House6   BATTERY  BATTERY_KW -0.037\n",
       "2  2018-08-01T02:01:00+02:00  House6   BATTERY  BATTERY_KW -0.033\n",
       "3  2018-08-01T02:02:00+02:00  House6   BATTERY  BATTERY_KW -0.041\n",
       "4  2018-08-01T02:03:00+02:00  House6   BATTERY  BATTERY_KW -0.034\n",
       "5  2018-08-01T02:04:00+02:00  House6   BATTERY  BATTERY_KW -0.033\n",
       "6  2018-08-01T02:05:00+02:00  House6   BATTERY  BATTERY_KW -0.025\n",
       "7  2018-08-01T02:06:00+02:00  House6   BATTERY  BATTERY_KW -0.028\n",
       "8  2018-08-01T02:07:00+02:00  House6   BATTERY  BATTERY_KW -0.028\n",
       "9  2018-08-01T02:08:00+02:00  House6   BATTERY  BATTERY_KW -0.028"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    path_heeten_data,\n",
    "    nrows=20000,\n",
    "    index_col=[\"timestamp\"],\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype=dtype,\n",
    "    names=[\"timestamp\", \"house\", \"appliance\", \"measurement\", \"value\"],\n",
    "    skiprows=7826*10000#7827*10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fromisoformat: argument must be str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m small_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromisoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: fromisoformat: argument must be str"
     ]
    }
   ],
   "source": [
    "small_df.index.values[0]\n",
    "datetime.fromisoformat(df.index.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-19 05:15:00+02:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 10, 19, 5, 15, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200)))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.index.values[1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 10, 19, 5, 14, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200)))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime('2018-10-19 05:14:00+02:00', \"%Y-%m-%d %H:%M:%S%z\")\n",
    "datetime.fromisoformat('2018-10-19 05:14:00+02:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-10-19 05:15:00+0200'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.strftime(\"%Y-%m-%d %H:%M:%S%z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kai\\AppData\\Local\\Temp\\ipykernel_17560\\2356270489.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df.index.to_series()[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-10-19 05:14:00+0200', tz='UTC+02:00')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.to_series()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0marg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DatetimeScalarOrArrayConvertible | DictConvertible'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DateTimeErrorChoices'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0myearfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mutc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexact\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0munit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'lib.NoDefault | bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0morigin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DatetimeIndex | Series | DatetimeScalar | NaTType | None'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Convert argument to datetime.\n",
      "\n",
      "This function converts a scalar, array-like, :class:`Series` or\n",
      ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
      "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
      "    method expects minimally the following columns: :const:`\"year\"`,\n",
      "    :const:`\"month\"`, :const:`\"day\"`. The column \"year\"\n",
      "    must be specified in 4-digit format.\n",
      "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
      "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
      "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
      "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
      "dayfirst : bool, default False\n",
      "    Specify a date parse order if `arg` is str or is list-like.\n",
      "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
      "    is parsed as :const:`2012-11-10`.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
      "        with day first.\n",
      "\n",
      "yearfirst : bool, default False\n",
      "    Specify a date parse order if `arg` is str or is list-like.\n",
      "\n",
      "    - If :const:`True` parses dates with the year first, e.g.\n",
      "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
      "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
      "      preceded (same as :mod:`dateutil`).\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
      "        with year first.\n",
      "\n",
      "utc : bool, default False\n",
      "    Control timezone-related parsing, localization and conversion.\n",
      "\n",
      "    - If :const:`True`, the function *always* returns a timezone-aware\n",
      "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
      "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
      "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
      "\n",
      "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
      "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
      "      will keep their time offsets. Limitations exist for mixed\n",
      "      offsets (typically, daylight savings), see :ref:`Examples\n",
      "      <to_datetime_tz_examples>` section for details.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        In a future version of pandas, parsing datetimes with mixed time\n",
      "        zones will raise an error unless `utc=True`.\n",
      "        Please specify `utc=True` to opt in to the new behaviour\n",
      "        and silence this warning. To create a `Series` with mixed offsets and\n",
      "        `object` dtype, please use `apply` and `datetime.datetime.strptime`.\n",
      "\n",
      "    See also: pandas general documentation about `timezone conversion and\n",
      "    localization\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "    #time-zone-handling>`_.\n",
      "\n",
      "format : str, default None\n",
      "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "    `strftime documentation\n",
      "    <https://docs.python.org/3/library/datetime.html\n",
      "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "    note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "    You can also pass:\n",
      "\n",
      "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "      time string (not necessarily in exactly the same format);\n",
      "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "      and you should probably use it along with `dayfirst`.\n",
      "\n",
      "    .. note::\n",
      "\n",
      "        If a :class:`DataFrame` is passed, then `format` has no effect.\n",
      "\n",
      "exact : bool, default True\n",
      "    Control how `format` is used:\n",
      "\n",
      "    - If :const:`True`, require an exact `format` match.\n",
      "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
      "      string.\n",
      "\n",
      "    Cannot be used alongside ``format='ISO8601'`` or ``format='mixed'``.\n",
      "unit : str, default 'ns'\n",
      "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
      "    integer or float number. This will be based off the origin.\n",
      "    Example, with ``unit='ms'`` and ``origin='unix'``, this would calculate\n",
      "    the number of milliseconds to the unix epoch start.\n",
      "infer_datetime_format : bool, default False\n",
      "    If :const:`True` and no `format` is given, attempt to infer the format\n",
      "    of the datetime strings based on the first non-NaN element,\n",
      "    and if it can be inferred, switch to a faster method of parsing them.\n",
      "    In some cases this can increase the parsing speed by ~5-10x.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "        A strict version of this argument is now the default, passing it has\n",
      "        no effect.\n",
      "\n",
      "origin : scalar, default 'unix'\n",
      "    Define the reference date. The numeric values would be parsed as number\n",
      "    of units (defined by `unit`) since this reference date.\n",
      "\n",
      "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
      "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
      "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
      "      to the day starting at noon on January 1, 4713 BC.\n",
      "    - If Timestamp convertible (Timestamp, dt.datetime, np.datetimt64 or date\n",
      "      string), origin is set to Timestamp identified by origin.\n",
      "    - If a float or integer, origin is the millisecond difference\n",
      "      relative to 1970-01-01.\n",
      "cache : bool, default True\n",
      "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
      "    datetime conversion. May produce significant speed-up when parsing\n",
      "    duplicate date strings, especially ones with timezone offsets. The cache\n",
      "    is only used when there are at least 50 values. The presence of\n",
      "    out-of-bounds values will render the cache unusable and may slow down\n",
      "    parsing.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "datetime\n",
      "    If parsing succeeded.\n",
      "    Return type depends on input (types in parenthesis correspond to\n",
      "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
      "    parsing):\n",
      "\n",
      "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
      "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
      "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
      "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
      "      :class:`Series` of :class:`object` dtype containing\n",
      "      :class:`datetime.datetime`)\n",
      "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
      "      :class:`Series` of :class:`object` dtype containing\n",
      "      :class:`datetime.datetime`)\n",
      "\n",
      "Raises\n",
      "------\n",
      "ParserError\n",
      "    When parsing a date from string fails.\n",
      "ValueError\n",
      "    When another datetime conversion error happens. For example when one\n",
      "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
      "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
      "    of mixed time offsets, and ``utc=False``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.astype : Cast argument to a specified dtype.\n",
      "to_timedelta : Convert argument to timedelta.\n",
      "convert_dtypes : Convert dtypes.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Many input types are supported, and lead to different output types:\n",
      "\n",
      "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
      "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
      "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
      "  None/NaN/null scalars are converted to :const:`NaT`.\n",
      "\n",
      "- **array-like** can contain int, float, str, datetime objects. They are\n",
      "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
      "  converted to :class:`Index` with :class:`object` dtype, containing\n",
      "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
      "  :const:`NaT` in both cases.\n",
      "\n",
      "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
      "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
      "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
      "  entries are converted to :const:`NaT` in both cases.\n",
      "\n",
      "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
      "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
      "  the various dataframe columns. Column keys can be common abbreviations\n",
      "  like ['year', 'month', 'day', 'minute', 'second', 'ms', 'us', 'ns']) or\n",
      "  plurals of the same.\n",
      "\n",
      "The following causes are responsible for :class:`datetime.datetime` objects\n",
      "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
      ":class:`object` dtype) instead of a proper pandas designated type\n",
      "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
      "with :class:`datetime64` dtype):\n",
      "\n",
      "- when any input element is before :const:`Timestamp.min` or after\n",
      "  :const:`Timestamp.max`, see `timestamp limitations\n",
      "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "  #timeseries-timestamp-limits>`_.\n",
      "\n",
      "- when ``utc=False`` (default) and the input is an array-like or\n",
      "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
      "  time offsets. Note that this happens in the (quite frequent) situation when\n",
      "  the timezone has a daylight savings policy. In that case you may wish to\n",
      "  use ``utc=True``.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "**Handling various input formats**\n",
      "\n",
      "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
      "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
      "'ms', 'us', 'ns']) or plurals of the same\n",
      "\n",
      ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
      "...                    'month': [2, 3],\n",
      "...                    'day': [4, 5]})\n",
      ">>> pd.to_datetime(df)\n",
      "0   2015-02-04\n",
      "1   2016-03-05\n",
      "dtype: datetime64[ns]\n",
      "\n",
      "Using a unix epoch time\n",
      "\n",
      ">>> pd.to_datetime(1490195805, unit='s')\n",
      "Timestamp('2017-03-22 15:16:45')\n",
      ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
      "Timestamp('2017-03-22 15:16:45.433502912')\n",
      "\n",
      ".. warning:: For float arg, precision rounding might happen. To prevent\n",
      "    unexpected behavior use a fixed-width exact type.\n",
      "\n",
      "Using a non-unix epoch origin\n",
      "\n",
      ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
      "...                origin=pd.Timestamp('1960-01-01'))\n",
      "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "**Differences with strptime behavior**\n",
      "\n",
      ":const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "\n",
      ">>> pd.to_datetime('2018-10-26 12:00:00.0000000011',\n",
      "...                format='%Y-%m-%d %H:%M:%S.%f')\n",
      "Timestamp('2018-10-26 12:00:00.000000001')\n",
      "\n",
      "**Non-convertible date/times**\n",
      "\n",
      "If a date does not meet the `timestamp limitations\n",
      "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "#timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
      "will return the original input instead of raising any exception.\n",
      "\n",
      "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
      "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
      "\n",
      ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
      "'13000101'\n",
      ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
      "NaT\n",
      "\n",
      ".. _to_datetime_tz_examples:\n",
      "\n",
      "**Timezones and time offsets**\n",
      "\n",
      "The default behaviour (``utc=False``) is as follows:\n",
      "\n",
      "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00:00', '2018-10-26 13:00:15'])\n",
      "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "- Timezone-aware inputs *with constant time offset* are converted to\n",
      "  timezone-aware :class:`DatetimeIndex`:\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
      "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
      "              dtype='datetime64[ns, UTC-05:00]', freq=None)\n",
      "\n",
      "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
      "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
      "  are **not successfully converted** to a :class:`DatetimeIndex`.\n",
      "  Parsing datetimes with mixed time zones will show a warning unless\n",
      "  `utc=True`. If you specify `utc=False` the warning below will be shown\n",
      "  and a simple :class:`Index` containing :class:`datetime.datetime`\n",
      "  objects will be returned:\n",
      "\n",
      ">>> pd.to_datetime(['2020-10-25 02:00 +0200',\n",
      "...                 '2020-10-25 04:00 +0100'])  # doctest: +SKIP\n",
      "FutureWarning: In a future version of pandas, parsing datetimes with mixed\n",
      "time zones will raise an error unless `utc=True`. Please specify `utc=True`\n",
      "to opt in to the new behaviour and silence this warning. To create a `Series`\n",
      "with mixed offsets and `object` dtype, please use `apply` and\n",
      "`datetime.datetime.strptime`.\n",
      "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
      "      dtype='object')\n",
      "\n",
      "- A mix of timezone-aware and timezone-naive inputs is also converted to\n",
      "  a simple :class:`Index` containing :class:`datetime.datetime` objects:\n",
      "\n",
      ">>> from datetime import datetime\n",
      ">>> pd.to_datetime([\"2020-01-01 01:00:00-01:00\",\n",
      "...                 datetime(2020, 1, 1, 3, 0)])  # doctest: +SKIP\n",
      "FutureWarning: In a future version of pandas, parsing datetimes with mixed\n",
      "time zones will raise an error unless `utc=True`. Please specify `utc=True`\n",
      "to opt in to the new behaviour and silence this warning. To create a `Series`\n",
      "with mixed offsets and `object` dtype, please use `apply` and\n",
      "`datetime.datetime.strptime`.\n",
      "Index([2020-01-01 01:00:00-01:00, 2020-01-01 03:00:00], dtype='object')\n",
      "\n",
      "|\n",
      "\n",
      "Setting ``utc=True`` solves most of the above issues:\n",
      "\n",
      "- Timezone-naive inputs are *localized* as UTC\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
      "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\n",
      "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
      "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
      "...                utc=True)\n",
      "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\n",
      "- Inputs can contain both string or datetime, the above\n",
      "  rules still apply\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00', datetime(2020, 1, 1, 18)], utc=True)\n",
      "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2020-01-01 18:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\u001b[1;31mFile:\u001b[0m      d:\\side-project\\continued\\manipulate-large-datasets\\.condapkg\\env\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:                            house   appliance measurement  value\n",
      "timestamp                                                       \n",
      "2018-10-01 00:00:00+02:00  House1  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-01 00:01:00+02:00  House1  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-01 00:03:00+02:00  House1  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-01 00:04:00+02:00  House1  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-01 00:05:00+02:00  House1  SMARTMETER   EXPORT_KW    0.0\n",
      "...                           ...         ...         ...    ...\n",
      "2018-10-31 23:53:00+01:00     NaN  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-31 23:54:00+01:00     NaN  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-31 23:55:00+01:00     NaN  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-31 23:57:00+01:00     NaN  SMARTMETER   EXPORT_KW    0.0\n",
      "2018-10-31 23:58:00+01:00     NaN  SMARTMETER   EXPORT_KW    0.0\n",
      "\n",
      "[20000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df.sort_index().loc[\n",
    "                    target_time_range[0][0] : target_time_range[0][1]\n",
    "                ]\n",
    "except Exception as e:\n",
    "    logging.exception(df.sort_index(), exc_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_2018 = datadir(\"Heeten_2018\")\n",
    "output_path_2019 = datadir(\"Heeten_2019\")\n",
    "\n",
    "# small_df.to_csv(output_path_2018, mode=\"a\", header=False) if output_path_2018.is_file() else small_df.to_csv(output_path_2018)\n",
    "with pd.read_csv(\n",
    "    path_heeten_data,\n",
    "    chunksize=10_000,\n",
    "    index_col=[\"timestamp\"],\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype=dtype,\n",
    ") as reader:\n",
    "    for chunk in tqdm(reader):\n",
    "        if chunk[\"measurement\"].isin(target_measurement).any():\n",
    "            # remove rows containing NaN (i.e. \"HouseTest\") in `house` column\n",
    "            chunk.dropna(subset=[\"house\"], inplace=True)\n",
    "            # picks up row containing target_measurement in `measurement` column\n",
    "            chunk.query(\"measurement in @target_measurement\", inplace=True)\n",
    "\n",
    "            if chunk.empty:\n",
    "                continue\n",
    "\n",
    "            # TODO:\n",
    "            # - async?\n",
    "            try:\n",
    "                chunk.sort_index().loc[\n",
    "                    target_time_range[0][0] : target_time_range[0][1]\n",
    "                ].to_parquet(output_path_2018, partition_cols=[\"house\", \"measurement\"])\n",
    "                chunk.sort_index().loc[\n",
    "                    target_time_range[1][0] : target_time_range[1][1]\n",
    "                ].to_parquet(output_path_2019, partition_cols=[\"house\", \"measurement\"])\n",
    "            except Exception as e:\n",
    "                logging.\n",
    "            # Write to 2018\n",
    "            # if output_path_2018.is_file():\n",
    "            #     chunk.sort_index().loc[\n",
    "            #         target_time_range[0][0] : target_time_range[0][1]\n",
    "            #     ].to_csv(output_path_2018, mode=\"a\", header=False)\n",
    "            # else:\n",
    "            #     chunk.sort_index().loc[\n",
    "            #         target_time_range[0][0] : target_time_range[0][1]\n",
    "            #     ].to_csv(output_path_2018)\n",
    "\n",
    "            # Write to 2019\n",
    "            # if output_path_2019.is_file():\n",
    "            #     chunk.sort_index().loc[\n",
    "            #         target_time_range[1][0] : target_time_range[1][1]\n",
    "            #     ].to_csv(output_path_2019, mode=\"a\", header=False)\n",
    "            # else:\n",
    "            #     chunk.sort_index().loc[\n",
    "            #         target_time_range[1][0] : target_time_range[1][1]\n",
    "            #     ].to_csv(output_path_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path_2018 = datadir(\"Heeten_2018\")\n",
    "# df = pd.read_parquet(output_path_2018, columns=[\"house\", \"appliance\", \"measurement\", \"value\"])\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
